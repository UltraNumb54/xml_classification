import os
import yaml
import numpy as np
from ultralytics import YOLO
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import gc  # Для управления памятью

# 1. Подготовка структуры данных
dataset_path = "ваш/путь/к/датасету"  # Укажите полный путь к папке с данными
images_dir = os.path.join(dataset_path, "images")
labels_dir = os.path.join(dataset_path, "labels")

# Прочитаем классы из файла
with open(os.path.join(dataset_path, "classes.txt"), "r") as f:
    classes = [line.strip() for line in f.readlines()]

# 2. Анализ датасета
print("Анализ датасета:")
all_images = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]
print(f"Всего изображений: {len(all_images)}")

# Подсчет количества аннотаций
annotation_count = 0
for img_name in all_images:
    txt_name = os.path.splitext(img_name)[0] + '.txt'
    txt_path = os.path.join(labels_dir, txt_name)
    if os.path.exists(txt_path):
        with open(txt_path, 'r') as f:
            annotation_count += len(f.readlines())

print(f"Всего аннотаций: {annotation_count}")
print(f"Среднее количество аннотаций на изображение: {annotation_count/len(all_images):.2f}")

# 3. Создание data.yaml
data = {
    'path': dataset_path,
    'train': 'train.txt',
    'val': 'val.txt',
    'names': {i: name for i, name in enumerate(classes)}
}

with open(os.path.join(dataset_path, 'data.yaml'), 'w') as f:
    yaml.dump(data, f)

# 4. Разделение на train/val
image_paths = [os.path.join(images_dir, f) for f in all_images]
train_files, val_files = train_test_split(image_paths, test_size=0.2, random_state=42)

# Создание файлов с путями
with open(os.path.join(dataset_path, 'train.txt'), 'w') as f:
    f.write('\n'.join(train_files))

with open(os.path.join(dataset_path, 'val.txt'), 'w') as f:
    f.write('\n'.join(val_files))

# Очистка памяти
del image_paths, train_files, val_files
gc.collect()

# 5. Инициализация модели
model = YOLO('yolov8n-obb.yaml')  # Создаем новую модель OBB

# 6. Обучение с безопасными параметрами для CPU
results = model.train(
    data=os.path.join(dataset_path, 'data.yaml'),
    epochs=30,  # Еще меньше эпох для начала
    imgsz=480,  # Уменьшаем размер изображения
    batch=4,  # Уменьшаем batch size
    augment=True,
    degrees=3.0,  # Еще меньше аугментации
    translate=0.03,
    scale=0.1,
    shear=0.5,
    perspective=0.0001,
    flipud=0.2,
    fliplr=0.2,
    mosaic=0.5,  # Уменьшаем вероятность мозаики
    mixup=0.0,  # Полностью отключаем mixup - очень ресурсоемкий
    cache=False,  # Отключаем кэширование - экономит RAM
    device='cpu',
    workers=2,  # Уменьшаем количество workers
    project='yolo_obb_train',
    name='exp1',
    patience=5,  # Ранняя остановка если нет улучшений 5 эпох
    save_period=10,  # Сохраняем реже
    val=True,
    plots=True,
    verbose=True  # Включаем подробный вывод для мониторинга
)

# 7. Оценка модели
from ultralytics.utils.metrics import ConfusionMatrix

# Загрузка лучшей модели
trained_model = YOLO(os.path.join('yolo_obb_train', 'exp1', 'weights', 'best.pt'))

# Тестирование на валидационном наборе
metrics = trained_model.val()
print(f"mAP50: {metrics.box.map50}")
print(f"mAP50-95: {metrics.box.map}")

# 8. Дополнительные рекомендации для экономии памяти
print("\nРекомендации для экономии памяти:")
print("1. Закройте все ненужные приложения во время обучения")
print("2. Убедитесь, что на системном диске достаточно свободного места")
print("3. Рассмотрите возможность использования более легкой модели (yolov8n вместо yolov8s)")
print("4. Если проблемы сохраняются, уменьшите imgsz до 416")
print("5. Мониторьте использование памяти во время обучения с помощью диспетчера задач")