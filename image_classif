import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt

# Настройки для экономии памяти
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    try:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)
    except:
        pass

# Параметры
IMG_SIZE = (224, 224)  # Размер изображений
BATCH_SIZE = 16        # Размер батча (уменьшите, если не хватает памяти)
EPOCHS = 50            # Количество эпох
NUM_CLASSES = 5        # Количество классов (папок)

# Пути к данным
train_data_dir = '/путь/к/вашей/папке/с/данными'  # Папка с подпапками для каждого класса

# Аугментация данных для увеличения разнообразия
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,  # Разделение на train/validation
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    shear_range=0.2,
    fill_mode='nearest'
)

# Загрузка тренировочных данных
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

# Загрузка валидационных данных
validation_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

# Проверяем количество изображений
print(f"Количество тренировочных изображений: {train_generator.samples}")
print(f"Количество валидационных изображений: {validation_generator.samples}")

# Создаем базовую модель с transfer learning
base_model = EfficientNetB0(
    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),
    include_top=False,
    weights='imagenet'
)

# Замораживаем базовые слои
base_model.trainable = False

# Создаем полную модель
model = keras.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.2),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(NUM_CLASSES, activation='softmax')
])

# Компилируем модель
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Выводим архитектуру модели
model.summary()

# Колбэки для обучения
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)

# Обучаем модель
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // BATCH_SIZE,
    epochs=EPOCHS,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

# Сохраняем модель
model.save('image_classifier.h5')

# Визуализация процесса обучения
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.savefig('training_history.png')
plt.show()

# Функция для предсказания на новых изображениях
def predict_image(image_path):
    img = keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0
    
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction, axis=1)
    
    # Получаем метки классов из train_generator
    class_labels = list(train_generator.class_indices.keys())
    
    return class_labels[predicted_class[0]], prediction[0][predicted_class[0]]

# Пример использования
# predicted_class, confidence = predict_image('/путь/к/изображению.jpg')
# print(f"Класс: {predicted_class}, Уверенность: {confidence:.2f}")